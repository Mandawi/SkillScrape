{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Companies</th>\n",
       "      <th>Positions</th>\n",
       "      <th>ID</th>\n",
       "      <th>Descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State Street</td>\n",
       "      <td>Software Engineer I (EMS Trading Team) - Charl...</td>\n",
       "      <td>e8a9b71f6c5126ae</td>\n",
       "      <td>['Opportunity to influence and impact the arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>Software Engineering Intern, BS, Winter 2020</td>\n",
       "      <td>1d99705341f0d46c</td>\n",
       "      <td>['1. In the “Resume Section:” attach an update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DataDog</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>f47387c886f1b1dd</td>\n",
       "      <td>['Build distributed, high-throughput, real-tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pluralsight</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>ddc20246b79174f2</td>\n",
       "      <td>['Provide architectural, strategic, and scale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Achievement Network (ANet)</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>a0303ea18678af0c</td>\n",
       "      <td>['Implement ANet’s next generation of technolo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Companies  \\\n",
       "0                State Street   \n",
       "1                      Google   \n",
       "2                     DataDog   \n",
       "3                 Pluralsight   \n",
       "4  Achievement Network (ANet)   \n",
       "\n",
       "                                           Positions                ID  \\\n",
       "0  Software Engineer I (EMS Trading Team) - Charl...  e8a9b71f6c5126ae   \n",
       "1       Software Engineering Intern, BS, Winter 2020  1d99705341f0d46c   \n",
       "2                                  Software Engineer  f47387c886f1b1dd   \n",
       "3                                  Software Engineer  ddc20246b79174f2   \n",
       "4                                  Software Engineer  a0303ea18678af0c   \n",
       "\n",
       "                                        Descriptions  \n",
       "0  ['Opportunity to influence and impact the arch...  \n",
       "1  ['1. In the “Resume Section:” attach an update...  \n",
       "2  ['Build distributed, high-throughput, real-tim...  \n",
       "3  ['Provide architectural, strategic, and scale ...  \n",
       "4  ['Implement ANet’s next generation of technolo...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = os.path.dirname(os.path.realpath('__file__')) + \"\\data\"\n",
    "df_software = pd.read_csv(data_directory+\"\\software_engineer.csv\")\n",
    "df_software.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Opportunity to influence and impact the arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['1. In the “Resume Section:” attach an update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Build distributed, high-throughput, real-tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Provide architectural, strategic, and scale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Implement ANet’s next generation of technolo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Descriptions\n",
       "0  ['Opportunity to influence and impact the arch...\n",
       "1  ['1. In the “Resume Section:” attach an update...\n",
       "2  ['Build distributed, high-throughput, real-tim...\n",
       "3  ['Provide architectural, strategic, and scale ...\n",
       "4  ['Implement ANet’s next generation of technolo..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_software = df_software.dropna()\n",
    "df_software = df_software[[\"Descriptions\"]]\n",
    "print(type(df_software))\n",
    "df_software.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Opportunity to influence and impact the archi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1. In the “Resume Section:” attach an updated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Build distributed, high-throughput, real-time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Provide architectural, strategic, and scale r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Implement ANet’s next generation of technolog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Descriptions\n",
       "0  [Opportunity to influence and impact the archi...\n",
       "1  [1. In the “Resume Section:” attach an updated...\n",
       "2  [Build distributed, high-throughput, real-time...\n",
       "3  [Provide architectural, strategic, and scale r...\n",
       "4  [Implement ANet’s next generation of technolog..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn all data from list literals to list\n",
    "for i in range (0, len(df_software)):\n",
    "    if type(df_software.iloc[i,0]) is str:\n",
    "        df_software.iloc[i,0] = ast.literal_eval(df_software.iloc[i,0])\n",
    "\n",
    "df_software.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "df_software.iloc[0][0][2]\n",
    "for data in df_software[\"Descriptions\"]:\n",
    "    print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_se = df_software[\"Descriptions\"].tolist()\n",
    "len(desc_se)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_se_flat = [item for sublist in desc_se for item in sublist]\n",
    "\n",
    "# create the rank of documents – we will use it later\n",
    "ranks = []\n",
    "for i in range(1, len(desc_se_flat)+1):\n",
    "    ranks.append(i)\n",
    "len(desc_se_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Opportunity influence impact architecture, standards, design key product initiatives applications Java services',\n",
       " 'Contribute Sr. Individual contributor within team top engineers',\n",
       " 'Work dynamic, fast-paced, Agile team environment',\n",
       " 'BS/MS Computer Science equivalent field',\n",
       " '3+ years commercial software development, proficient developing multi-tier solutions']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuations\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df_stopwords = pd.DataFrame({'descs':desc_se_flat})\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df_stopwords['descs'] = df_stopwords['descs'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df_stopwords\n",
    "desc_se_flat = df_stopwords[\"descs\"].tolist()\n",
    "desc_se_flat[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# Load 'stemmer'\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for sentence tokenizer, to remove numeric tokens and raw punctuation\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "def tokenize_only(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 7850)\n",
      "  (0, 4929)\t0.17743746587167045\n",
      "  (0, 3727)\t0.17743746587167045\n",
      "  (0, 3567)\t0.17264559939088153\n",
      "  (0, 529)\t0.14895401805525083\n",
      "  (0, 6668)\t0.1534023937405399\n",
      "  (0, 1955)\t0.10971647619477819\n",
      "  (0, 3999)\t0.1684946958388015\n",
      "  (0, 5389)\t0.11621622033271585\n",
      "  (0, 3748)\t0.17743746587167045\n",
      "  (0, 458)\t0.11550157734889074\n",
      "  (0, 3901)\t0.12261525509304118\n",
      "  (0, 6244)\t0.13185549725911921\n",
      "  (0, 4932)\t0.19898436235309114\n",
      "  (0, 3730)\t0.1831050409852232\n",
      "  (0, 3568)\t0.1831050409852232\n",
      "  (0, 543)\t0.1831050409852232\n",
      "  (0, 6671)\t0.17743746587167045\n",
      "  (0, 1990)\t0.1831050409852232\n",
      "  (0, 4002)\t0.1831050409852232\n",
      "  (0, 5401)\t0.1831050409852232\n",
      "  (0, 3749)\t0.1831050409852232\n",
      "  (0, 491)\t0.19898436235309114\n",
      "  (0, 3930)\t0.17743746587167045\n",
      "  (0, 4933)\t0.19898436235309114\n",
      "  (0, 3731)\t0.1831050409852232\n",
      "  :\t:\n",
      "  (662, 4348)\t0.1671037662089728\n",
      "  (663, 2046)\t0.09036326564983015\n",
      "  (663, 6513)\t0.1354035771870305\n",
      "  (663, 5334)\t0.1463354649491617\n",
      "  (663, 5878)\t0.16033148000186215\n",
      "  (663, 5719)\t0.19862564732951413\n",
      "  (663, 5034)\t0.15358533579231382\n",
      "  (663, 1672)\t0.20797235646308396\n",
      "  (663, 2358)\t0.20797235646308396\n",
      "  (663, 1673)\t0.20797235646308396\n",
      "  (663, 4105)\t0.2211458030981143\n",
      "  (663, 5042)\t0.2211458030981143\n",
      "  (663, 2359)\t0.2211458030981143\n",
      "  (663, 5886)\t0.2211458030981143\n",
      "  (663, 2143)\t0.2211458030981143\n",
      "  (663, 6533)\t0.2211458030981143\n",
      "  (663, 5721)\t0.2211458030981143\n",
      "  (663, 4106)\t0.2211458030981143\n",
      "  (663, 5043)\t0.2211458030981143\n",
      "  (663, 1674)\t0.2211458030981143\n",
      "  (663, 2360)\t0.2211458030981143\n",
      "  (663, 5887)\t0.2211458030981143\n",
      "  (663, 2144)\t0.2211458030981143\n",
      "  (663, 6534)\t0.2211458030981143\n",
      "  (663, 5722)\t0.2211458030981143\n"
     ]
    }
   ],
   "source": [
    "# tfidf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, max_features=200000, min_df=1, stop_words='english', use_idf=True,\n",
    "                                   tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "#fit the vectorizer to data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(desc_se_flat)\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "print(tfidf_matrix.shape)\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 2, 4, 4, 3, 1, 4, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1, 4, 4, 3, 2, 4, 4, 1, 1, 2, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 3, 4, 3, 3, 1, 1, 1, 1, 2, 3, 0, 3, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 3, 4, 1, 1, 1, 0, 1, 3, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 2, 4, 3, 1, 1, 1, 1, 1, 1, 2, 2, 4, 2, 4, 1, 2, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 0, 3, 0, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 2, 4, 3, 3, 2, 4, 4, 1, 4, 1, 1, 1, 1, 1, 0, 1, 1, 1, 3, 1, 0, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 0, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 3, 1, 0, 1, 3, 3, 2, 0, 1, 1, 3, 1, 1, 3, 4, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 3, 2, 1, 3, 1, 1, 4, 3, 3, 4, 2, 4, 4, 3, 1, 4, 1, 1, 1, 1, 0, 1, 1, 1, 2, 3, 1, 1, 1, 1, 3, 3, 1, 0, 3, 1, 1, 1, 0, 1, 2, 4, 4, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 3, 3, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 4, 1, 1, 1, 1, 2, 2, 1, 4, 4, 3, 2, 4, 4, 1, 1, 2, 1, 4, 3, 4, 3, 3, 2, 4, 4, 1, 4, 1, 1, 1, 1, 1, 0, 1, 1, 1, 3, 1, 3, 1, 0, 1, 1, 1, 1, 1, 0, 3, 3, 1, 2, 1, 1, 3, 1, 1, 3, 1, 0, 3, 3, 3, 1, 3, 1, 1, 3, 1, 3, 1, 1, 4, 2, 3, 3, 0, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 4, 4, 0, 1, 0, 1, 3, 3, 1, 2, 1, 1, 1, 1, 3, 0, 0, 3, 1, 0, 1, 1, 1, 1, 2, 4, 4, 4, 4, 4, 4, 4, 1, 1, 0, 3, 3, 1, 1, 1, 1, 3, 3, 1, 0, 1, 4, 1, 3, 1, 1, 1, 0, 0, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 4, 1, 1, 0, 1, 1, 3, 0, 3, 1, 3, 1, 4, 3, 0, 1, 1, 1, 1, 1, 1, 2, 4, 0, 2, 4, 1, 0, 0, 1, 3, 3, 0, 1, 3, 0, 2, 4, 1, 1, 1, 4, 3, 0, 1, 1, 0, 1, 1, 1, 2, 3, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 3, 1, 1, 1, 3, 3, 1, 4, 3, 4, 4, 2, 4, 4, 4, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0, 3, 1, 0, 1, 1, 1, 1, 3, 3, 1, 2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 4, 2, 3, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#Import Kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define number of clusters\n",
    "num_clusters = 5\n",
    "\n",
    "#Running clustering algorithm\n",
    "km = KMeans(n_clusters=num_clusters, init=\"k-means++\")\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "#final clusters\n",
    "clusters = km.labels_.tolist()\n",
    "print(clusters)\n",
    "description_data = {'rank': ranks, 'descriptions': desc_se_flat, 'cluster': clusters }\n",
    "frame = pd.DataFrame(complaints_data, index = [clusters], columns = ['rank', 'cluster'])\n",
    "\n",
    "#number of docs per cluster\n",
    "# frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 words:  b'design', b'design', b'development', b'familiar', b'strong', b'oo', b'oo', b'oo',\n",
      "Cluster 1 words:  b'experience', b'skills', b'communication', b'strong', b'software', b'testing', b'development', b'data',\n",
      "Cluster 2 words:  b'computer', b'degree', b'science', b'computer', b'field', b'degree', b'degree', b'related',\n",
      "Cluster 3 words:  b'work', b'team', b'environment', b'agile', b'experience', b'ability', b'fast-paced', b'ability',\n",
      "Cluster 4 words:  b'years', b'development', b'java', b'experience', b'development', b'software', b'software', b'years',\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in desc_se_flat:\n",
    "    allwords_stemmed = tokenize_and_stem(i)\n",
    "    totalvocab_stemmed.extend(allwords_stemmed)\n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)\n",
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end=\" \")\n",
    "    for ind in order_centroids[i, :8]:\n",
    "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
